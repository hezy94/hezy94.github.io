---
layout: post
title: '爬取廖雪峰老师git教程并且做成pdf'
date: 2018-03-14
tags: 爬虫
---


## 一、前言
本文的主要内容是爬取廖雪峰老师git教程并且做成pdf。网上也有[现成的教程](http://blog.csdn.net/shenwanjiang111/article/details/68925569)了，但是还是想用自己的想法实现了一遍。其中涉及的东西有：
- pdfkit
- wkhtmltopdf
- 爬虫
- re库(正则表达式)
- HTML/CSS
- Python
- ...

## 二、准备工作
本次代码的编写的编写环境：
- 系统环境：macOS High Sierra 10.13.3版本
- IDE：PyCharm
- Python版本：2.7.10

一开始需要在PyCharm中安装pdfkit的库，同时还要安装wkhtmltopdf，这个需要安装在系统中，wkhtmltopdf的下载地址:[https://wkhtmltopdf.org/downloads.html](https://wkhtmltopdf.org/downloads.html)

## 三、代码的编写

### 获取每节的标题与url地址
```Python
aListsNames = []
aListsUrls = []
headers = {"User-Agent": headerLists[random.randint(0,16)]}
proxies = get_random_ip(get_ip_list(proxyURL,headers))
r = requests.get("https://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000",headers=headers,proxies=proxies)
html = r.text
soup = BeautifulSoup(html,'html.parser')
ulList = soup.find(id='x-wiki-index')
aLists = ulList.find_all('a')
for i in range(len(aLists)):
    aListsNames.append(aLists[i].text)
    aListsUrls.append(aLists[i]['href'])
for i in range(len(aListsUrls)):
    aListsUrls[i] = "https://www.liaoxuefeng.com"+aListsUrls[i]
```

### 获取每节的主要内容
因为pdfkit这个工具，是可以直接将html文件转化为pdf文件的，所以为本节的思路是建立一个html模板，然后每次将每节的主要内容以 Python中文件操作'a+'的方式继续增加内容。最后合成一个html，集中转化为pdf文件。

```Python
f = open('pdf.html', 'a+')
#输入html头文件
html_template_head = """
<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
</head>
<style>
.titles{text-align:center;font-size:50px}
</style>
<body>
"""
f.write(html_template_head)

#输入中间的内容
for i in range(len(aListsUrls)):
    headers = {"User-Agent": headerLists[random.randint(0, 16)]}
    proxies = get_random_ip(get_ip_list(url, headers))
    html = requests.get(url=aListsUrls[i], headers=headers,proxies=proxies).text
    soup = BeautifulSoup(html, 'html.parser')
    mainContent = soup.find('div','x-main-content')
    f.write("<div class='titles'><a href='"+str(aListsUrls[i])+"'>"+str(aListsNames[i])+"</a></div>")
    f.write(str(mainContent))

#输入html文件底部的内容
html_template_foot="""
</body>
</html>
"""
f.write(html_template_foot)
f.close()
```

### html文件内容的整理
在查看html.pdf文件的过程中，发现两个问题。
1. 网站中的img图片的原地址都是在**data-src**中，而代码中的src地址，都是一个加载的gif动画，后来发现把**data-src**地址直接改为src就ok了，就能加载出原来的图片了
2. 最新的网站中添加的视频，但是pdf根本用不了视频功能呀。。。后来发现，把**video**标签中的
**controls**删除，视频就只剩下图片了。如果真的看不过去，在最后生成的html文件中，将其去除。
```Python
with open('pdf.html') as f:
    contents= f.read()
    contents=re.sub(r'data-src', 'src', contents)
    contents=re.sub(r'controls=""', ' ', contents)
with open('pdf.html','w') as f:
    f.write(contents)
```

### 将html文件转化为pdf文件
pdfkit的工具可能还有很多用处，其他用处可以参考[地址1](http://blog.csdn.net/shenwanjiang111/article/details/68925569)、[地址2](http://pdfkit.org)
```Python
pdfkit.from_file('pdf.html','git教程.pdf')
```

## 四、其他问题
在代码编写的过程中，最大的问题就是遇到了来自网站的干涉。。出现了**503 Service Unavailable for Bot**的提示。
做出的尝试有：
1. 使用其他的headers
```
headerLists = [
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.47 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36",
    "Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; AcooBrowser; .NET CLR 1.1.4322; .NET CLR 2.0.50727)",
    "Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 6.0; Acoo Browser; SLCC1; .NET CLR 2.0.50727; Media Center PC 5.0; .NET CLR 3.0.04506)",
    "Mozilla/4.0 (compatible; MSIE 7.0; AOL 9.5; AOLBuild 4337.35; Windows NT 5.1; .NET CLR 1.1.4322; .NET CLR 2.0.50727)",
    "Mozilla/5.0 (Windows; U; MSIE 9.0; Windows NT 9.0; en-US)",
    "Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Win64; x64; Trident/5.0; .NET CLR 3.5.30729; .NET CLR 3.0.30729; .NET CLR 2.0.50727; Media Center PC 6.0)",
    "Mozilla/5.0 (compatible; MSIE 8.0; Windows NT 6.0; Trident/4.0; WOW64; Trident/4.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; .NET CLR 1.0.3705; .NET CLR 1.1.4322)",
    "Mozilla/4.0 (compatible; MSIE 7.0b; Windows NT 5.2; .NET CLR 1.1.4322; .NET CLR 2.0.50727; InfoPath.2; .NET CLR 3.0.04506.30)",
    "Mozilla/5.0 (Windows; U; Windows NT 5.1; zh-CN) AppleWebKit/523.15 (KHTML, like Gecko, Safari/419.3) Arora/0.3 (Change: 287 c9dfb30)",
    "Mozilla/5.0 (X11; U; Linux; en-US) AppleWebKit/527+ (KHTML, like Gecko, Safari/419.3) Arora/0.6",
    "Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.8.1.2pre) Gecko/20070215 K-Ninja/2.1.1",
    "Mozilla/5.0 (Windows; U; Windows NT 5.1; zh-CN; rv:1.9) Gecko/20080705 Firefox/3.0 Kapiko/3.0",
    "Mozilla/5.0 (X11; Linux i686; U;) Gecko/20070322 Kazehakase/0.4.5",
    "Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.8) Gecko Fedora/1.9.0.8-1.fc10 Kazehakase/0.5.6",
    "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.11 (KHTML, like Gecko) Chrome/17.0.963.56 Safari/535.11"
]
```
2. 使用proxy
3. 使用`time.sleep(1)`来实现间歇性的访问

接下去，然后呢，最后发现：

这些东西并没有什么乱用，该被制裁的还是要被制裁。所以要使用代码来直接输入一个pdf文件，我可能目前没什么办法了。。。


## 五、参考资料
- [廖雪峰git教程网页版](https://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000)
- [pdfkit工具介绍](http://blog.csdn.net/shenwanjiang111/article/details/68925569)
- [pdfkit官网](http://pdfkit.org)
- [markdown语法健忘提醒](http://blog.csdn.net/witnessai1/article/details/52551362)
- [Python文件打开方式详解](http://blog.csdn.net/ztf312/article/details/47259805)
- [Python抓取HTML网页并以PDF保存](http://blog.csdn.net/hubaoquanu/article/details/66973149)
- [Python深入浅出-PyPDF2处理PDF文件](http://blog.csdn.net/xingxtao/article/details/79056341)
